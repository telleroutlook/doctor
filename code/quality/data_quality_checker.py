"""æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·"""

from __future__ import annotations

import logging
from collections import Counter
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from statistics import mean
from typing import Dict, List

from database.models import Article as ArticleModel
from database.setup_database import DatabaseManager

logger = logging.getLogger(__name__)


@dataclass
class ArticleQualityResult:
    article_id: int
    url: str
    title: str
    language: str
    version: str
    word_count: int
    issues: List[str]

    @property
    def passed(self) -> bool:
        return not self.issues


class DataQualityChecker:
    """é’ˆå¯¹çˆ¬å–ç»“æœçš„è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self, sqlite_path=None, min_title_length=5, min_word_count=150):
        self.db_manager = DatabaseManager(use_sqlite=True, sqlite_path=sqlite_path)
        self.min_title_length = min_title_length
        self.min_word_count = min_word_count

    def run_checks(self, sample_size=50) -> Dict[str, object]:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥å¹¶è¿”å›è¯¦ç»†æŠ¥å‘Š"""
        articles = self._fetch_articles(sample_size)
        evaluations = [self._evaluate(article) for article in articles]
        summary = self._summarize(evaluations)
        report = self._render_report(summary, evaluations)
        return {
            'evaluations': evaluations,
            'summary': summary,
            'report': report
        }

    def _fetch_articles(self, sample_size):
        session = self.db_manager.get_session()
        try:
            query = session.query(ArticleModel).order_by(ArticleModel.updated_at.desc())
            if sample_size:
                query = query.limit(sample_size)
            return query.all()
        finally:
            session.close()

    def _evaluate(self, article: ArticleModel) -> ArticleQualityResult:
        title = (article.title or '').strip()
        content = (article.content or '').strip()
        language = (article.language or '').strip()
        version = (article.version or '').strip()
        word_count = article.word_count or len(content.split())

        issues = []
        if len(title) < self.min_title_length:
            issues.append('æ ‡é¢˜è¿‡çŸ­æˆ–ç¼ºå¤±')
        if not content:
            issues.append('æ­£æ–‡ç¼ºå¤±')
        if word_count < self.min_word_count:
            issues.append('å­—æ•°ä¸è¶³')
        if not language:
            issues.append('è¯­è¨€ç¼ºå¤±')
        if not version:
            issues.append('ç‰ˆæœ¬ç¼ºå¤±')
        if not article.category:
            issues.append('åˆ†ç±»ç¼ºå¤±')
        if not article.url:
            issues.append('URLç¼ºå¤±')
        elif not article.url.startswith('http'):
            issues.append('URLæ ¼å¼å¼‚å¸¸')

        return ArticleQualityResult(
            article_id=article.id,
            url=article.url or '',
            title=title or 'ï¼ˆç©ºæ ‡é¢˜ï¼‰',
            language=language or 'æœªæ ‡æ³¨',
            version=version or 'æœªæ ‡æ³¨',
            word_count=word_count,
            issues=issues
        )

    def _summarize(self, evaluations: List[ArticleQualityResult]) -> Dict[str, object]:
        total = len(evaluations)
        passed = sum(1 for item in evaluations if item.passed)
        failed = total - passed
        avg_words = round(mean([item.word_count for item in evaluations]) if evaluations else 0, 2)

        issue_counter = Counter()
        for item in evaluations:
            for issue in item.issues:
                issue_counter[issue] += 1

        return {
            'total_checked': total,
            'passed': passed,
            'failed': failed,
            'pass_rate': round((passed / total) * 100, 2) if total else 0,
            'average_word_count': avg_words,
            'issue_breakdown': dict(issue_counter)
        }

    def _render_report(self, summary: Dict[str, object], evaluations: List[ArticleQualityResult]) -> str:
        lines = [
            'ğŸ©º æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š',
            '====================',
            f"æ£€æŸ¥æ—¶é—´: {datetime.now().isoformat(timespec='seconds')}",
            f"æŠ½æ ·æ•°é‡: {summary['total_checked']}",
            f"é€šè¿‡æ¡ç›®: {summary['passed']} ({summary['pass_rate']}%)",
            f"æœªé€šè¿‡æ¡ç›®: {summary['failed']}",
            f"å¹³å‡å­—æ•°: {summary['average_word_count']}",
            '',
            'é—®é¢˜åˆ†å¸ƒ:'
        ]

        if summary['issue_breakdown']:
            for issue, count in summary['issue_breakdown'].items():
                lines.append(f"- {issue}: {count}")
        else:
            lines.append('- æœªå‘ç°è´¨é‡é—®é¢˜')

        failing_items = [item for item in evaluations if not item.passed]
        if failing_items:
            lines.append('\nç¤ºä¾‹é—®é¢˜æ¡ç›®:')
            for item in failing_items[:5]:
                lines.append(f"- [{item.article_id}] {item.title} ({item.url}) -> {', '.join(item.issues)}")

        return '\n'.join(lines)

    def save_report(self, report_text: str, output_dir='logs') -> Path:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        report_file = output_dir / f"data_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_file.write_text(report_text, encoding='utf-8')
        logger.info("è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: %s", report_file)
        return report_file
